# -*- coding: utf-8 -*-
"""streamlit_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lLQsyfP93BQqDNGMjVjPsp8GRCRXHE3g
"""

!pip install streamlit pyngrok pandas numpy pillow scikit-learn openpyxl pytesseract pypdf2

!apt-get install tesseract-ocr

# Commented out IPython magic to ensure Python compatibility.
# %%writefile streamlit_app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import io
# import re
# from PIL import Image
# import pytesseract
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LogisticRegression
# from sklearn.metrics import accuracy_score
# import PyPDF2 # Import PyPDF2 for PDF processing
# 
# #confgure
# st.set_page_config(page_title="SafeBite", layout="wide")
# st.title("SafeBite - Smarter menus, safer meals ")
# 
# #load data
# def load_data():
#     return pd.read_excel("SafeBite_dataset.xlsx")
# 
# df = load_data()
# 
# #rename 'Restaurnt name' to 'restaurant_name'
# if 'Restaurnt name' in df.columns:
#     df.rename(columns={'Restaurnt name': 'restaurant_name'}, inplace=True)
# 
# #rename 'Food Name' to 'food_name'
# if 'Food Name' in df.columns:
#     df.rename(columns={'Food Name': 'food_name'}, inplace=True)
# 
# #check if 'full_ingredient_list' column exists in the initial DataFrame
# if 'full_ingredient_list' not in df.columns:
#     found_ingredient_col = False
#     for col in df.columns:
#         if 'ingredient' in col.lower() and 'list' in col.lower():
#             df.rename(columns={col: 'full_ingredient_list'}, inplace=True)
#             found_ingredient_col = True
#             break
#     if not found_ingredient_col:
#         df['full_ingredient_list'] = ""
# 
# #'allergy_safety_status' column
# if 'allergy_safety_status' not in df.columns:
#     df['allergy_safety_status'] = 'caution'
# 
# allergy = [
#     "milk", "eggs", "wheat_gluten", "soy", "peanuts", "tree_nuts", "fish", "shellfish", "sesame"
# ]
# 
# allergen_keywords = {
#     "milk": ["milk", "cheese", "butter", "cream", "yogurt", "ghee", "whey", "casein", "lactose"],
#     "eggs": ["egg", "eggs", "albumin"],
#     "wheat_gluten": ["wheat", "gluten", "flour", "bread", "pasta"],
#     "soy": ["soy", "soya", "tofu", "edamame"],
#     "peanuts": ["peanut", "groundnut"],
#     "tree_nuts": ["almond", "cashew", "walnut", "pistachio", "hazelnut"],
#     "fish": ["fish", "salmon", "tuna", "cod"],
#     "shellfish": ["shrimp", "prawn", "crab", "lobster"],
#     "sesame": ["sesame", "tahini"]
# }
# 
# #checking if all allergy columns exist and are numeric (0 or 1)
# for alg in allergy:
#     if alg not in df.columns:
#         df[alg] = 0
#     else:
#         df[alg] = pd.to_numeric(df[alg], errors='coerce').fillna(0).astype(int)
# 
# #user allergies
# st.sidebar.header("Your Allergies")
# 
# user_allergies = {}
# for allergen in allergy:
#     user_allergies[allergen] = st.sidebar.checkbox(allergen.replace("_", " ").title())
# 
# custom_input = st.sidebar.text_input(
#     "Other allergies (comma seperated)",
#     placeholder = "mustard, kiwi"
# )
# custom_allergies = [a.strip().lower() for a in custom_input.split(",") if a.strip()]
# 
# use_ml = st.sidebar.checkbox("Use AI model for risk review", value=True)
# 
# #ocr function (to upload menu image)
# def extract_text_from_image(uploaded_file):
#     image = Image.open(io.BytesIO(uploaded_file.read()))
#     text = pytesseract.image_to_string(image)
#     return text.lower()
# 
# def extract_text_from_pdf(uploaded_file):
#     reader = PyPDF2.PdfReader(uploaded_file)
#     text = ""
#     for page in reader.pages:
#         text += page.extract_text() or ""
#     return text.lower()
# 
# def parse_menu_text(text, restaurant_name):
#     lines = [l.strip() for l in text.split("\n") if len(l.strip()) > 3]
# 
#     rows = []
#     for line in lines:
#         rows.append({
#             "restaurant_name": restaurant_name,
#             "restaurant_type": "uploaded",
#             "menu_selection": "Unknown",
#             "food_name": line.title(),
#             "full_ingredient_list": line,
#             "allergy_safety_status": "caution",
#             **{a: 0 for a in allergy}
#         })
# 
#     return pd.DataFrame(rows)
# 
# #retaurant menu upload
# st.sidebar.markdown("---")
# st.sidebar.header("Restaurant upload")
# 
# uploaded_file = st.sidebar.file_uploader(
#     "Upload restaurant menu",
#     type=None
# )
# 
# 
# if uploaded_file:
#     file_name = uploaded_file.name.lower()
# 
#     try:
#         if file_name.endswith(".csv"):
#             upload_df = pd.read_csv(uploaded_file)
# 
#         elif file_name.endswith((".xlsx", ".xls")):
#             upload_df = pd.read_excel(uploaded_file)
# 
#         elif file_name.endswith( ".pdf"):
#             st.sidebar.info("Extracting menu from PDF ")
#             text = extract_text_from_pdf(uploaded_file)
#             upload_df = parse_menu_text(text, uploaded_file.name.split('.')[0]) # Use filename as restaurant name
# 
#         elif file_name.endswith( (".png", ".jpg", ".jpeg") ):
#             st.sidebar.info("Extracting menu from image(OCR) ")
#             text = extract_text_from_image(uploaded_file)
#             upload_df = parse_menu_text(text, "Uploaded Image Menu")
# 
#         else:
#             st.sidebar.error("Unsupported file format.")
#             upload_df = None
# 
#         if upload_df is not None:
#             for alg in allergy:
#                 if alg not in upload_df.columns:
#                     upload_df[alg] = 0
#                 else:
#                     upload_df[alg] = pd.to_numeric(upload_df[alg], errors='coerce').fillna(0).astype(int)
# 
#             required_cols =(
#                 ["restaurant_name", "food_name", "full_ingredient_list", "allergy_safety_status"]
#                 + allergy
#             )
# 
#             missing = [c for c in required_cols if c not in upload_df.columns]
# 
#             if missing:
#                 st.sidebar.error(f"Missing columns: {missing}")
#             else:
#                 if 'Restaurnt name' in upload_df.columns:
#                     upload_df.rename(columns={'Restaurnt name': 'restaurant_name'}, inplace=True)
#                 df = pd.concat([df, upload_df], ignore_index=True)
#                 df.to_excel("SafeBite_dataset.xlsx", index=False) # Save updated df back to Excel
#                 st.sidebar.success("Menu uploaded successfully and saved to SafeBite_dataset.xlsx")
# 
#     except Exception as e:
#         st.sidebar.error(f"Failed to process uploaded file: {e}")
# 
# #rule based safety logic
# def rule_based_safety(row):
#     ingredients = row["full_ingredient_list"].lower()
# 
#     #if no allergies are detected
#     if not any(user_allergies.values()) and not custom_allergies:
#       return "safe", ["No allergies detected"]
# 
#     reasons = []
# 
#     #allergy detection
#     for allergen, selected in user_allergies.items():
#       if not selected:
#         continue
# 
#       if row.get(allergen, 0) == 1:
#             reasons.append(f"Contains {allergen.replace("_"," ")}")
# 
#       for keyword in allergen_keywords.get(allergen, []):
#         if keyword in ingredients:
#             reasons.append(f"Contains {keyword}")
# 
#     for allergy in custom_allergies:
#         if allergy in ingredients:
#             reasons.append(f"Ingredient mantions {allergy}")
# 
#     if reasons:
#         return "unsafe", reasons
# 
#     # if row["allergy_safety_status"] == "caution":
#     #     return "caution", ["Possible cross contaminatio or unclear ingredients"]
# 
#     return "safe", ["No selected allergens were detected"]
# 
# #model
# @st.cache_resource
# def train_model(df):
#     tfidf = TfidfVectorizer(max_features=500)
#     X_text = tfidf.fit_transform(df["full_ingredient_list"])
# 
#     X_allergens = df[allergy].values
#     X = np.hstack([X_text.toarray(), X_allergens])
# 
#     y = df["allergy_safety_status"].map({
#         "safe": 0,
#         "caution": 1,
#         "unsafe": 2
#     })
# 
#     #check if there is enough diversity in the target variable
#     if len(y.unique()) < 2:
#         st.warning("Warning: Not enough diverse data to train the ML model. Defaulting to rule-based predictions.")
#         #dummy model that always predicts the single existing class
#         class DummyModel:
#             def predict(self, X):
#                 #ensure y is not empty before accessing iloc
#                 if not y.empty:
#                     return np.full(X.shape[0], y.iloc[0])
#                 else:
#                     #fallback if y is also empty (should ideally not happen if X is not empty)
#                     return np.full(X.shape[0], 1) #dfault to 'caution' if no data available
# 
#         model = DummyModel()
#         vectorizer = tfidf
#         acc = 0.0
#         return model, vectorizer, acc
# 
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
# 
#     model = LogisticRegression(max_iter=1000)
#     model.fit(X_train, y_train)
# 
#     acc = accuracy_score(y_test, model.predict(X_test))
#     return model, tfidf, acc
# 
# model, vectorizer, model_acc = train_model(df)
# 
# #search UI
# st.markdown("Search menu")
# col1, col2 = st.columns(2)
# 
# with col1:
#     restaurant = st.selectbox(
#         "Select Restaurant",
#         sorted(df["restaurant_name"].unique())
#     )
# 
# with col2:
#     query = st.text_input("Search dish (optional)")
# 
# menu_df = df[df["restaurant_name"] == restaurant]
# if query:
#     menu_df = menu_df[menu_df["food_name"].str.contains(query, case=False)]
# 
# #display results
# st.markdown(f"{restaurant} Menu")
# 
# for _, row in menu_df.iterrows():
#     rule_status, explanation = rule_based_safety(row)
#     final_status = rule_status
# 
#     if use_ml:
#         text_vec = vectorizer.transform([row["full_ingredient_list"]])
#         allergen_vec = row[allergy].values.reshape(1,-1)
#         X_input = np.hstack([text_vec.toarray(), allergen_vec])
# 
#         ml_pred = model.predict(X_input)[0]
#         ml_label = {0: "safe", 1: "caution", 2: "unsafe"}[ml_pred]
# 
#         if rule_status == "caution" and ml_label == "safe":
#           final_status = "Safe"
# 
#         elif rule_status == "safe" and ml_label == "unsafe":
#           final_status = "Caution"
# 
#     if final_status == "unsafe":
#         st.error(f"{row['food_name']} - Unsafe")
#     elif final_status == "caution":
#         st.warning(f"{row['food_name']} - Caution")
#     else:
#         st.success(f"{row['food_name']} - Safe")
# 
#     with st.expander("Why this result?"):
#         for reason in explanation:
#             st.write(f"-{reason}")
# 
# #footer
# st.markdown("---")

from pyngrok import ngrok
import subprocess
import os

#kill any running ngrok tunnels to free up port 8501
os.system("kill $(lsof -t -i:8501)")

#authenticate ngrok
from google.colab import userdata
NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN') #get token form https://dashboard.ngrok.com/
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

#start streamlit in the background
!streamlit run streamlit_app.py &>/dev/null &

import time
time.sleep(5)

#set up tunnel to port 8501 (streamlit default)
public_url = ngrok.connect(addr='8501')
print("Streamlit app URL:", public_url)

















